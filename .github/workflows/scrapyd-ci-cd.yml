name: Scrapyd CI/CD

on:
  push:
    branches:
      - main
  schedule:
    - cron: "*/14 * * * *"   # trigger every 14 minutes
  workflow_dispatch:          # allow manual run

jobs:
  deploy_and_ping:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        working-directory: ./newscraper
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install scrapyd-client

      - name: Deploy to Scrapyd
        working-directory: ./newscraper/jobscrapper
        run: |
          scrapyd-deploy jobscrapper

      - name: Ping Scrapyd Backends
        run: |
          echo "Pinging Scrapyd at $(date)"
          curl -s https://jobapp-backend-25kl.onrender.com/ || echo "Ping to jobapp-backend failed"
          curl -s https://jobapp-bah2.onrender.com/daemonstatus.json || echo "Ping to jobapp-bah2 failed"
          curl -s https://workoutbuddy-9nqn.onrender.com/ || echo "Ping to workoutBuddy-backend failed"
          curl -s https://workoutbuddyfrontend-kn9e.onrender.com/ || echo "Ping to workoutBuddy-Frontend failed"
          

